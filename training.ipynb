{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayingCardDataset(Dataset):\n",
    "  def __init__(self, data_dir, transform=None):\n",
    "    self.data = ImageFolder(data_dir, transform=transform)\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx]\n",
    "  def classes(self):\n",
    "    return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PlayingCardDataset(\n",
    "  data_dir = 'archive/train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ace of clubs', 1: 'ace of diamonds', 2: 'ace of hearts', 3: 'ace of spades', 4: 'eight of clubs', 5: 'eight of diamonds', 6: 'eight of hearts', 7: 'eight of spades', 8: 'five of clubs', 9: 'five of diamonds', 10: 'five of hearts', 11: 'five of spades', 12: 'four of clubs', 13: 'four of diamonds', 14: 'four of hearts', 15: 'four of spades', 16: 'jack of clubs', 17: 'jack of diamonds', 18: 'jack of hearts', 19: 'jack of spades', 20: 'joker', 21: 'king of clubs', 22: 'king of diamonds', 23: 'king of hearts', 24: 'king of spades', 25: 'nine of clubs', 26: 'nine of diamonds', 27: 'nine of hearts', 28: 'nine of spades', 29: 'queen of clubs', 30: 'queen of diamonds', 31: 'queen of hearts', 32: 'queen of spades', 33: 'seven of clubs', 34: 'seven of diamonds', 35: 'seven of hearts', 36: 'seven of spades', 37: 'six of clubs', 38: 'six of diamonds', 39: 'six of hearts', 40: 'six of spades', 41: 'ten of clubs', 42: 'ten of diamonds', 43: 'ten of hearts', 44: 'ten of spades', 45: 'three of clubs', 46: 'three of diamonds', 47: 'three of hearts', 48: 'three of spades', 49: 'two of clubs', 50: 'two of diamonds', 51: 'two of hearts', 52: 'two of spades'}\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'archive/train'\n",
    "target_to_class = {v: k for k, v in ImageFolder(data_dir).class_to_idx.items()}\n",
    "print(target_to_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATALOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.Resize((128, 128)),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_dir = 'archive/train'\n",
    "dataset = PlayingCardDataset(data_dir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 128])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = dataset[100]\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in dataset:\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in dataloader:\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCardClassifier(nn.Module):\n",
    "  def __init__(self, num_classes = 53):\n",
    "    super(SimpleCardClassifier, self).__init__()\n",
    "    \n",
    "    self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "    self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "\n",
    "    enet_out_size = 1280\n",
    "    self.classifier = nn.Linear(enet_out_size, num_classes)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    output = self.classifier(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCardClassifier(num_classes=53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6378, -0.1952, -0.2676,  ...,  0.1909,  0.4693,  0.2446],\n",
       "        [ 0.1678, -0.0547,  0.1278,  ..., -0.1037,  0.3094, -0.0679],\n",
       "        [-0.0081,  0.3479, -0.3992,  ...,  0.0475,  0.0380,  0.0162],\n",
       "        ...,\n",
       "        [-0.0488,  0.0768, -0.4368,  ...,  0.4016, -0.0284, -0.5741],\n",
       "        [ 0.2388, -0.0911, -0.2712,  ..., -0.3123, -0.0832, -0.0626],\n",
       "        [ 0.0603,  0.0422,  0.4072,  ...,  0.2880, -0.1689,  0.1341]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 53])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_out = model(images)\n",
    "example_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0386, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(example_out, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.Resize((128,128)),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_folder = 'archive/train/' \n",
    "valid_folder = 'archive/valid/'\n",
    "test_folder = 'archive/test/'\n",
    "\n",
    "train_dataset = PlayingCardDataset(train_folder, transform=transform)\n",
    "valid_dataset = PlayingCardDataset(valid_folder, transform=transform)\n",
    "test_dataset = PlayingCardDataset(test_folder, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "training_losses, val_losses = [], []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleCardClassifier(num_classes=53)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  for images, labels in train_dataloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item() * labels.size(0)\n",
    "  training_loss = running_loss / len(train_dataloader.dataset)\n",
    "  training_losses.append(training_loss)\n",
    "\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  with torch.no_grad():\n",
    "    for images, labels in valid_dataloader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      running_loss += loss.item() * labels.size(0)\n",
    "  val_loss = running_loss / len(valid_dataloader.dataset)\n",
    "  val_losses.append(val_loss)\n",
    "\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {training_loss}, Valid Loss: {val_loss}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
